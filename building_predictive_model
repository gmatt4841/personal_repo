import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from dmba import regressionSummary 

housing_df = pd.read_csv('/Users/matthewgarcia/Library/Mobile Documents/com~apple~CloudDocs/WestRoxbury.csv')
#print(housing_df.shape) #find dimension of data frame
#print(housing_df.head()) #show first five rows
# print(housing_df) #show all data 

#rename columns: replace space with '_' to allow dot notation 
houseing_df = housing_df.rename(columns={'TOTAL VALUE' : 'TOTAL_VALUE'}) #explicit
housing_df.columns = [s.strip().replace(' ', '_') for s in housing_df.columns] # all columns

# Practice showing the first four rows of the data 
# print(housing_df.loc[0:3])  # show first four rows
# print(housing_df.iloc[0:4]) # show first four rows

#Different ways of showing the first 10 values in column total_value 
# print(housing_df['TOTAL_VALUE'].iloc[0:10])
# print(housing_df.iloc[0:10]['TOTAL_VALUE'])
# print(housing_df.iloc[0:10].TOTAL_VALUE) #use dot notation if the column name has no spaces 

# show the fifth row of the first 10 columns 
# print(housing_df.iloc[4][0:10]) 
# print(housing_df.iloc[4, 0:10]) 
# print(housing_df.iloc[4:5, 0:10]) 

#use pd.concat to combine non-consecutive columns into a new data frame 
# the axis argument specifies the dimension along which the 
# concatenation happens, 0=rows, 1=columns 
# print(pd.concat([housing_df.iloc[4:6,0:2], housing_df.iloc[4:6, 4:6]], axis=1))

# random sampling of 5 observations
# print(housing_df.sample(5))

# oversample houses with over 10 rooms 
weights = [0.9 if rooms > 10 else 0.1 for rooms in housing_df.ROOMS]
housing_df.sample(5, weights=weights)

# reviewing variables 
print(housing_df.columns)
housing_df.REMODEL = housing_df.REMODEL.astype('category')
print(housing_df.REMODEL.cat.categories) #show number of categories
print(housing_df.REMODEL.dtype) #show number of categories 

#use drop_first = True to drop the first dummy variable 
housing_df = pd.get_dummies(housing_df, prefix_sep='_', drop_first=True).astype(int)
print('Now:', housing_df.columns)
print(housing_df.loc[:, 'REMODEL_Recent'].head(5))

#to illustrate missing data procedures, we first convert a few entries for 
# bedrooms to na's.  Then we inpute these missing values using the median of the 
# remaining values 
missingRows = housing_df.sample(10).index
housing_df.loc[missingRows, 'BEDROOMS'] = np.nan
print('Number of rows with valid BEDROOMS values after settingto NAN: ', housing_df['BEDROOMS'].count())

# # remove rows with missing values
reduced_df = housing_df.dropna()
print('Number of rows after removing rows with missing values: ', len(reduced_df))

# # replace the missing values using the median of the remaining values 
medianBedrooms = housing_df['BEDROOMS'].median()
housing_df.BEDROOMS = housing_df.BEDROOMS.fillna(value=medianBedrooms)
print('Number of rows with valid BEDROOMS values afer filling NA alues:  ', housing_df['BEDROOMS'].count())

# normalizing a data frame 
df = housing_df.copy()
print(df.dtypes)  # Check column data types
df = pd.get_dummies(df, prefix_sep='_', drop_first=True).astype(int)
print('Updated Columns:', df.columns)

#normalizing methods 
#norm_df = (housing_df - housing_df.mean()) / housing_df.std() #pandas method
scaler = StandardScaler()
norm_df = pd.DataFrame(scaler.fit_transform(housing_df), index =housing_df.index, columns=housing_df.columns) #scikit-learn method
norm_df_p = (housing_df-housing_df.mean())/housing_df.std() #pandas method

#rescaling a dataframe 
#pandas method 
norm_df_p = (housing_df -housing_df.min())/ (housing_df.max() - housing_df.min())

#scikit-learn method
scaler = MinMaxScaler()
norm_df = pd.DataFrame(scaler.fit_transform(housing_df), index=housing_df.index, columns=housing_df.columns)

#data partitioning in python 
#training (60%) and validation (40%) 
trainData, validData = train_test_split(housing_df, test_size=0.40, random_state=1)

print('Training : ', trainData.shape)
print('Validation : ', validData.shape) 
print()

#training (60%), validation (20%), and test (20%)
trainData, temp = train_test_split(housing_df, test_size=0.5, random_state=1)
validData, testData = train_test_split(temp, test_size=0.4, random_state=1) 

print('Training : ', trainData.shape)
print('Validation : ', validData.shape) 
print('Test : ', testData.shape)

#building a predictive model
#data loading and preprocessing
housing_df2 = pd.read_csv('/Users/matthewgarcia/Library/Mobile Documents/com~apple~CloudDocs/WestRoxbury.csv')
housing_df2.columns = [s.strip().replace(' ', '_') for s in housing_df2.columns]
housing_df2 = pd.get_dummies(housing_df2, prefix_sep='_', drop_first=True).astype(int)

#create list of predictors and outcome 
excludeColumns = ('TOTAL_VALUE', 'TAX')
predictors = [s for s in housing_df2.columns if s not in excludeColumns]
outcome = 'TOTAL_VALUE'

#partition data 
X = housing_df2[predictors]
y = housing_df2[outcome]
train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)

model = LinearRegression()
model.fit(train_X, train_y)

train_pred = model.predict(train_X)
train_results = pd.DataFrame({
    'TOTAL_VALUE': train_y, 
    'predicted': train_pred, 
    'residual': train_y - train_pred
})
print(train_results.head())

valid_pred = model.predict(valid_X)
valid_results = pd.DataFrame({
    'TOTAL_VALUE': valid_y, 
    'predicted': valid_pred, 
    'residual': valid_y - valid_pred
})
print(valid_results.head())

#training set
regressionSummary(train_results.TOTAL_VALUE, train_results.predicted) 

#validation set
regressionSummary(valid_results.TOTAL_VALUE, valid_results.predicted)

#predictions 
new_data = pd.DataFrame({
    'LOT_SQFT': [4200, 6444, 5035], 
    'YR_BUILT': [1980, 1940, 1925], 
    'GROSS_AREA': [2500, 3000, 3500], 
    'LIVING_AREA': [1600, 2000, 2400], 
    'FLOORS': [2, 2, 2], 
    'ROOMS': [7, 8, 9], 
    'BEDROOMS': [3, 4, 5], 
    'FULL_BATH': [1, 2, 2], 
    'HALF_BATH': [1, 1, 1], 
    'KITCHEN': [1, 1, 1], 
    'FIREPLACE': [1, 1, 1], 
    'REMODEL_Recent': [0, 0, 1]
})

print(new_data)
print('predictions: ', model.predict(new_data))
